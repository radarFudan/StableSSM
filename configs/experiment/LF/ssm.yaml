# @package _global_
defaults:
  - /experiment/LF/base.yaml
  - override /model: stablessm.yaml

tags: ["lf", "stablessm"]

model:
  _target_: src.models.lf_module.LFLitModule
  optimizer:
    lr: 0.01
    weight_decay: 0.01
  scheduler:
    T_max: ${trainer.max_epochs}
  net:
    rec1_size: 64
    n_layers: 1
    dropout: 0.0
    parameterization: "direct"
    return_seq: True
  encoder:
    _target_: src.models.encoders.linear.Linear
    in_size: 1
    out_size: ${model.net.rec1_size}
  decoder:
    _target_: src.models.decoders.linear.Linear
    in_size: ${model.net.rec1_size}
    out_size: 1

data:
  batch_size: 128

trainer:
  min_epochs: 10
  max_epochs: 10
  # gradient_clip_val: 0.5

logger:
  wandb:
    project: "StableSSM_LF_SSM"
